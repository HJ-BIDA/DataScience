{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml.dataframe as dataframe\n",
    "from notebook_hana_connector.notebook_hana_connector import NotebookConnectionContext\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from xgboost import XGBRegressor\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = NotebookConnectionContext(connectionId = 'hanapoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171595fb",
   "metadata": {},
   "source": [
    "Get 10000 COMPLETED rows from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "\"select \"\n",
    "\"top 10000 \"\n",
    "\"*, \"\n",
    "\"(ORD_LINE_CANC / (ORD_LINE_COMP + ORD_LINE_CANC)) as ORD_CANC_RATIO, \"\n",
    "\"(CUST_LINES_CANC / (CUST_LINES_COMP + CUST_LINES_CANC)) as CUST_CANC_RATIO, \"\n",
    "\"(PLANT_LINES_CANC / (PLANT_LINES_COMP + PLANT_LINES_CANC)) as PLANT_CANC_RATIO \"\n",
    "\"from VW_BWH_TRAIN_LINE_ORD_CUST_DEPOT \"\n",
    "\"where NET_VALUE > '0' \"\n",
    "\"and COMP_FLAG = '1' \"\n",
    "\"ORDER BY RAND() LIMIT 10000\"\n",
    ")\n",
    "\n",
    "po_sel = conn.sql(sql)\n",
    "comp = po_sel.collect()\n",
    "#comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079665c",
   "metadata": {},
   "source": [
    "Get 10000 NOT-COMPLETED rows from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "\"select \"\n",
    "\"top 10000 \"\n",
    "\"*, \"\n",
    "\"(ORD_LINE_CANC / (ORD_LINE_COMP + ORD_LINE_CANC)) as ORD_CANC_RATIO, \"\n",
    "\"(CUST_LINES_CANC / (CUST_LINES_COMP + CUST_LINES_CANC)) as CUST_CANC_RATIO, \"\n",
    "\"(PLANT_LINES_CANC / (PLANT_LINES_COMP + PLANT_LINES_CANC)) as PLANT_CANC_RATIO \"\n",
    "\"from VW_BWH_TRAIN_LINE_ORD_CUST_DEPOT \"\n",
    "\"where NET_VALUE > '0' \"\n",
    "\"and COMP_FLAG = '0' \"\n",
    "\"ORDER BY RAND() LIMIT 10000\"\n",
    ")\n",
    "\n",
    "po_sel = conn.sql(sql)\n",
    "delet = po_sel.collect()\n",
    "#delet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c8840",
   "metadata": {},
   "source": [
    "Combine and format the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b68776",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([comp,delet])\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc13183",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['NET_VALUE'] = combined_df['NET_VALUE'].astype(float).astype(int)\n",
    "combined_df['ORD_NET_VALUE_TOTAL'] = combined_df['ORD_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "combined_df['ORD_NET_VALUE_COMP'] = combined_df['ORD_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "combined_df['ORD_NET_VALUE_CANC'] = combined_df['ORD_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "combined_df['CUST_NET_VALUE_TOTAL'] = combined_df['CUST_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "combined_df['CUST_NET_VALUE_COMP'] = combined_df['CUST_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "combined_df['CUST_NET_VALUE_CANC'] = combined_df['CUST_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "combined_df['PLANT_NET_VALUE_TOTAL'] = combined_df['PLANT_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "combined_df['PLANT_NET_VALUE_COMP'] = combined_df['PLANT_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "combined_df['PLANT_NET_VALUE_CANC'] = combined_df['PLANT_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "combined_df['ORD_CANC_RATIO'] = combined_df['ORD_CANC_RATIO'].astype(float)\n",
    "combined_df['CUST_CANC_RATIO'] = combined_df['CUST_CANC_RATIO'].astype(float)\n",
    "combined_df['PLANT_CANC_RATIO'] = combined_df['PLANT_CANC_RATIO'].astype(float)\n",
    "#include region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['COMP_FLAG']\n",
    "data = combined_df.drop(['CANC_FLAG','COMP_FLAG','DOC_NUMBER','S_ORD_ITEM','CUSTOMER','CUST_NAME','CUST_CITY','CUST_POSTAL_CD','PLANT','PLANT_NAME','MATERIAL','ORDSTAT','CREATEDON_SO','CREATEDON_LINE','LINE_COMP_DATE','K8INV_DT','RECORDMODE'], axis=1)\n",
    "#include region\n",
    "#x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9dc8fd",
   "metadata": {},
   "source": [
    "Fit a label binarizer to region column to do one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_encoder = LabelBinarizer()\n",
    "jobs_encoder.fit(data['REGION'])\n",
    "transformed = jobs_encoder.transform(data['REGION'])\n",
    "ohe_df = pd.DataFrame(transformed, columns=jobs_encoder.classes_)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "x = pd.concat([data, ohe_df], axis=1)\n",
    "x = x.drop(['REGION'], axis = 1)\n",
    "x.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e206a82",
   "metadata": {},
   "source": [
    "Fit a XGBoost classification model to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', eval_metric='logloss', n_estimators=300, early_stopping_rounds=50, verbose_eval=50, learning_rate=0.005, max_depth=7)\n",
    "#model = XGBClassifier(objective='binary:logistic', eval_metric='error@0.15', n_estimators=300, early_stopping_rounds=50, verbose_eval=50, learning_rate=0.005, max_depth=7)\n",
    "\n",
    "#error@t\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e330181",
   "metadata": {},
   "source": [
    "Get 10000 rows from the test dataset (note: this dataset is different from the training dataset (no overlap, and exists in time AFTER the training dataset as to avoid leaking information via the characteristics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a544bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "\"select \"\n",
    "\"top 10000 \"\n",
    "\"*, \"\n",
    "\"(ORD_LINE_CANC / (ORD_LINE_COMP + ORD_LINE_CANC)) as ORD_CANC_RATIO, \"\n",
    "\"(CUST_LINES_CANC / (CUST_LINES_COMP + CUST_LINES_CANC)) as CUST_CANC_RATIO, \"\n",
    "\"(PLANT_LINES_CANC / (PLANT_LINES_COMP + PLANT_LINES_CANC)) as PLANT_CANC_RATIO \"\n",
    "\"from VW_BWH_TEST_LINE_ORD_CUST_DEPOT \"\n",
    "\"where NET_VALUE > '0' \"\n",
    "\"ORDER BY RAND() LIMIT 10000\"\n",
    ")\n",
    "\n",
    "po_sel = conn.sql(sql)\n",
    "test = po_sel.collect()\n",
    "#delet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc74c7",
   "metadata": {},
   "source": [
    "Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f319aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['NET_VALUE'] = test['NET_VALUE'].astype(float).astype(int)\n",
    "test['ORD_NET_VALUE_TOTAL'] = test['ORD_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "test['ORD_NET_VALUE_COMP'] = test['ORD_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "test['ORD_NET_VALUE_CANC'] = test['ORD_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "test['CUST_NET_VALUE_TOTAL'] = test['CUST_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "test['CUST_NET_VALUE_COMP'] = test['CUST_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "test['CUST_NET_VALUE_CANC'] = test['CUST_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "test['PLANT_NET_VALUE_TOTAL'] = test['PLANT_NET_VALUE_TOTAL'].astype(float).astype(int)\n",
    "test['PLANT_NET_VALUE_COMP'] = test['PLANT_NET_VALUE_COMP'].astype(float).astype(int)\n",
    "test['PLANT_NET_VALUE_CANC'] = test['PLANT_NET_VALUE_CANC'].astype(float).astype(int)\n",
    "test['ORD_CANC_RATIO'] = test['ORD_CANC_RATIO'].astype(float)\n",
    "test['CUST_CANC_RATIO'] = test['CUST_CANC_RATIO'].astype(float)\n",
    "test['PLANT_CANC_RATIO'] = test['PLANT_CANC_RATIO'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf768c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['COMP_FLAG']\n",
    "datatest = test.drop(['CANC_FLAG','COMP_FLAG','DOC_NUMBER','S_ORD_ITEM','CUSTOMER','CUST_NAME','CUST_CITY','CUST_POSTAL_CD','PLANT','PLANT_NAME','MATERIAL','ORDSTAT','CREATEDON_SO','CREATEDON_LINE','LINE_COMP_DATE','K8INV_DT','RECORDMODE'], axis=1)\n",
    "#include region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a0386",
   "metadata": {},
   "source": [
    "Apply the SAME label binarizer as was trained on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caad3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtransformed = jobs_encoder.transform(datatest['REGION'])\n",
    "ohe_dftest = pd.DataFrame(testtransformed, columns=jobs_encoder.classes_)\n",
    "datatest.reset_index(inplace=True, drop=True)\n",
    "x_test = pd.concat([datatest, ohe_dftest], axis=1)\n",
    "x_test = x_test.drop(['REGION'], axis = 1)\n",
    "x_test.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af999781",
   "metadata": {},
   "source": [
    "Calculate accuracy for the predictions, using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d203988",
   "metadata": {},
   "source": [
    "Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e46f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cmd_obj = ConfusionMatrixDisplay(confm, display_labels=[model.classes_[0], model.classes_[1]])\n",
    "cmd_obj.plot()\n",
    "cmd_obj.ax_.set(\n",
    "                title='Confusion Matrix', \n",
    "                xlabel='Predicted', \n",
    "                ylabel='Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8a90d",
   "metadata": {},
   "source": [
    "Looks terrible! Lets try to alter the decision threshold to 17%..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict_proba(x_test)[:,1] >= 0.17).astype(bool) # set threshold as 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd78e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512056f0",
   "metadata": {},
   "source": [
    "Confusion matrix again. Looks a lot better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "confm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cmd_obj = ConfusionMatrixDisplay(confm, display_labels=[model.classes_[0], model.classes_[1]])\n",
    "cmd_obj.plot()\n",
    "cmd_obj.ax_.set(\n",
    "                title='Confusion Matrix', \n",
    "                xlabel='Predicted', \n",
    "                ylabel='Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95006d88",
   "metadata": {},
   "source": [
    "Show the test lines that the model is most certain about will be cancelled or completed respectfully (just change the ascending between True or False...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a59ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = pd.DataFrame(model.predict_proba(x_test))\n",
    "comparison = y_test_proba.join(y_test).join(test[['DOC_NUMBER','CANC_FLAG','S_ORD_ITEM']])\n",
    "comparison = comparison.sort_values(by=comparison.columns[1], ascending = True)\n",
    "comparison.rename(columns={list(comparison)[0]: 'Proba_Cancel', list(comparison)[1]: 'Proba_Invoice'}, inplace=True)\n",
    "cols = comparison.columns.tolist()\n",
    "#['DOC_NUMBER', 'S_ORD_ITEM', 'Proba_Cancel', 'Proba_Invoice', 'COMP_FLAG']\n",
    "#comparison.head(250)\n",
    "comparison2 = comparison[['DOC_NUMBER', 'S_ORD_ITEM', 'Proba_Cancel', 'Proba_Invoice', 'COMP_FLAG']]\n",
    "comparison2.head(250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
